	t","time":"2018-03-09T08:40:29.847944489Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Starting task 1406547.0 in stage 0.0 (TID 1406547, 172.31.2.18, executor 1, partition 1406547, PROCESS_LOCAL, 4844 bytes)\n","stream":"stdout","time":"2018-03-09T08:40:29.848808669Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Finished task 1406545.0 in stage 0.0 (TID 1406545) in 2 ms on 172.31.2.18 (executor 1) (1406546/10000000)\n","stream":"stdout","time":"2018-03-09T08:40:29.848839118Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Starting task 1406548.0 in stage 0.0 (TID 1406548, 172.31.4.37, executor 2, partition 1406548, PROCESS_LOCAL, 4844 bytes)\n","stream":"stdout","time":"2018-03-09T08:40:29.849664862Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Finished task 1406546.0 in stage 0.0 (TID 1406546) in 2 ms on 172.31.4.37 (executor 2) (1406547/10000000)\n","stream":"stdout","time":"2018-03-09T08:40:29.849945447Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Starting task 1406549.0 in stage 0.0 (TID 1406549, 172.31.2.18, executor 1, partition 1406549, PROCESS_LOCAL, 4844 bytes)\n","stream":"stdout","time":"2018-03-09T08:40:29.850671053Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Finished task 1406547.0 in stage 0.0 (TID 1406547) in 2 ms on 172.31.2.18 (executor 1) (1406548/10000000)\n","stream":"stdout","time":"2018-03-09T08:40:29.851431978Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Starting task 1406550.0 in stage 0.0 (TID 1406550, 172.31.4.37, executor 2, partition 1406550, PROCESS_LOCAL, 4844 bytes)\n","stream":"stdout","time":"2018-03-09T08:40:29.851456534Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Finished task 1406548.0 in stage 0.0 (TID 1406548) in 2 ms on 172.31.4.37 (executor 2) (1406549/10000000)\n","stream":"stdout","time":"2018-03-09T08:40:29.851765723Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Starting task 1406551.0 in stage 0.0 (TID 1406551, 172.31.2.18, executor 1, partition 1406551, PROCESS_LOCAL, 4844 bytes)\n","stream":"stdout","time":"2018-03-09T08:40:29.852774722Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Finished task 1406549.0 in stage 0.0 (TID 1406549) in 2 ms on 172.31.2.18 (executor 1) (1406550/10000000)\n","stream":"stdout","time":"2018-03-09T08:40:29.852846035Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Starting task 1406552.0 in stage 0.0 (TID 1406552, 172.31.4.37, executor 2, partition 1406552, PROCESS_LOCAL, 4844 bytes)\n","stream":"stdout","time":"2018-03-09T08:40:29.853651006Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Finished task 1406550.0 in stage 0.0 (TID 1406550) in 2 ms on 172.31.4.37 (executor 2) (1406551/10000000)\n","stream":"stdout","time":"2018-03-09T08:40:29.853678324Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSetManager:54 - Starting task 1406553.0 in stage 0.0 (TID 1406553, 172.31.2.18, executor 1, partition 1406553, PROCESS_LOCAL, 4844 bytes)\n","stream":"stdout","time":"2018-03-09T08:40:29.854618755Z"}
	{"log":"2018-03-09 08:40:29 ERROR KubernetesTaskSetManager:70 - Total size of serialized results of 1406552 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)\n","stream":"stdout","time":"2018-03-09T08:40:29.856822243Z"}
	{"log":"2018-03-09 08:40:29 ERROR KubernetesTaskSetManager:70 - Total size of serialized results of 1406553 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)\n","stream":"stdout","time":"2018-03-09T08:40:29.8606217Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool \n","stream":"stdout","time":"2018-03-09T08:40:29.864331889Z"}
	{"log":"2018-03-09 08:40:29 ERROR KubernetesTaskSetManager:70 - Total size of serialized results of 1406554 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)\n","stream":"stdout","time":"2018-03-09T08:40:29.865479399Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool \n","stream":"stdout","time":"2018-03-09T08:40:29.865868419Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesTaskSchedulerImpl:54 - Cancelling stage 0\n","stream":"stdout","time":"2018-03-09T08:40:29.866946257Z"}
	{"log":"2018-03-09 08:40:29 INFO  DAGScheduler:54 - ResultStage 0 (reduce at SparkPi.scala:38) failed in 1702.747 s due to Job aborted due to stage failure: Total size of serialized results of 1406552 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)\n","stream":"stdout","time":"2018-03-09T08:40:29.871084827Z"}
	{"log":"2018-03-09 08:40:29 INFO  DAGScheduler:54 - Job 0 failed: reduce at SparkPi.scala:38, took 1743.745592 s\n","stream":"stdout","time":"2018-03-09T08:40:29.880082758Z"}
	{"log":"Exception in thread \"main\" org.apache.spark.SparkException: Job aborted due to stage failure: Total size of serialized results of 1406552 tasks (1024.0 MB) is bigger than spark.driver.maxResultSize (1024.0 MB)\n","stream":"stderr","time":"2018-03-09T08:40:29.881298559Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\n","stream":"stderr","time":"2018-03-09T08:40:29.881423969Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\n","stream":"stderr","time":"2018-03-09T08:40:29.881437062Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\n","stream":"stderr","time":"2018-03-09T08:40:29.881442524Z"}
	{"log":"\u0009at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n","stream":"stderr","time":"2018-03-09T08:40:29.881452337Z"}
	{"log":"\u0009at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n","stream":"stderr","time":"2018-03-09T08:40:29.881462679Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\n","stream":"stderr","time":"2018-03-09T08:40:29.881496732Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n","stream":"stderr","time":"2018-03-09T08:40:29.881507866Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n","stream":"stderr","time":"2018-03-09T08:40:29.881605722Z"}
	{"log":"\u0009at scala.Option.foreach(Option.scala:257)\n","stream":"stderr","time":"2018-03-09T08:40:29.881616688Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n","stream":"stderr","time":"2018-03-09T08:40:29.881619456Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\n","stream":"stderr","time":"2018-03-09T08:40:29.881626728Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\n","stream":"stderr","time":"2018-03-09T08:40:29.881629708Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\n","stream":"stderr","time":"2018-03-09T08:40:29.881710926Z"}
	{"log":"\u0009at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n","stream":"stderr","time":"2018-03-09T08:40:29.881722004Z"}
	{"log":"\u0009at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n","stream":"stderr","time":"2018-03-09T08:40:29.88172473Z"}
	{"log":"\u0009at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n","stream":"stderr","time":"2018-03-09T08:40:29.88173245Z"}
	{"log":"\u0009at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119)\n","stream":"stderr","time":"2018-03-09T08:40:29.881817158Z"}
	{"log":"\u0009at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026)\n","stream":"stderr","time":"2018-03-09T08:40:29.881826927Z"}
	{"log":"\u0009at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n","stream":"stderr","time":"2018-03-09T08:40:29.881829573Z"}
	{"log":"\u0009at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n","stream":"stderr","time":"2018-03-09T08:40:29.881832447Z"}
	{"log":"\u0009at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n","stream":"stderr","time":"2018-03-09T08:40:29.881926149Z"}
	{"log":"\u0009at org.apache.spark.rdd.RDD.reduce(RDD.scala:1008)\n","stream":"stderr","time":"2018-03-09T08:40:29.881932284Z"}
	{"log":"\u0009at org.apache.spark.examples.SparkPi$.main(SparkPi.scala:38)\n","stream":"stderr","time":"2018-03-09T08:40:29.881934872Z"}
	{"log":"\u0009at org.apache.spark.examples.SparkPi.main(SparkPi.scala)\n","stream":"stderr","time":"2018-03-09T08:40:29.88193752Z"}
	{"log":"2018-03-09 08:40:29 INFO  SparkContext:54 - Invoking stop() from shutdown hook\n","stream":"stdout","time":"2018-03-09T08:40:29.887826818Z"}
	{"log":"2018-03-09 08:40:29 INFO  AbstractConnector:310 - Stopped Spark@58d78b89{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n","stream":"stdout","time":"2018-03-09T08:40:29.899406247Z"}
	{"log":"2018-03-09 08:40:29 INFO  SparkUI:54 - Stopped Spark web UI at http://spark-pi-1520583038503-driver-svc.default.svc.cluster.local:4040\n","stream":"stdout","time":"2018-03-09T08:40:29.907788938Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesClusterSchedulerBackend:54 - Shutting down all executors\n","stream":"stdout","time":"2018-03-09T08:40:29.921645074Z"}
	{"log":"2018-03-09 08:40:29 INFO  KubernetesClusterSchedulerBackend$KubernetesDriverEndpoint:54 - Asking each executor to shut down\n","stream":"stdout","time":"2018-03-09T08:40:29.922866245Z"}
	{"log":"2018-03-09 08:40:30 INFO  KubernetesClusterSchedulerBackend:54 - Closing kubernetes client\n","stream":"stdout","time":"2018-03-09T08:40:30.027529716Z"}
	{"log":"2018-03-09 08:40:30 INFO  KubernetesClusterSchedulerBackend:54 - Received delete pod spark-pi-1520583038503-exec-3 event. Reason: null\n","stream":"stdout","time":"2018-03-09T08:40:30.027755057Z"}
	{"log":"2018-03-09 08:40:30 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!\n","stream":"stdout","time":"2018-03-09T08:40:30.046512909Z"}
	{"log":"2018-03-09 08:40:30 INFO  MemoryStore:54 - MemoryStore cleared\n","stream":"stdout","time":"2018-03-09T08:40:30.065408828Z"}
	{"log":"2018-03-09 08:40:30 INFO  BlockManager:54 - BlockManager stopped\n","stream":"stdout","time":"2018-03-09T08:40:30.066624069Z"}
	{"log":"2018-03-09 08:40:30 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped\n","stream":"stdout","time":"2018-03-09T08:40:30.068544748Z"}
	{"log":"2018-03-09 08:40:30 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!\n","stream":"stdout","time":"2018-03-09T08:40:30.074439723Z"}
	{"log":"2018-03-09 08:40:30 INFO  SparkContext:54 - Successfully stopped SparkContext\n","stream":"stdout","time":"2018-03-09T08:40:30.086720008Z"}
	{"log":"2018-03-09 08:40:30 INFO  ShutdownHookManager:54 - Shutdown hook called\n","stream":"stdout","time":"2018-03-09T08:40:30.087848702Z"}
	{"log":"2018-03-09 08:40:30 INFO  ShutdownHookManager:54 - Deleting directory /mnt/tmp/spark-local/spark-3c7b6b41-5b92-4e20-adf8-f71b0f0c02e6/spark-188c896e-eb3c-4af0-ba8a-ebd6c1ab8543\n","stream":"stdout","time":"2018-03-09T08:40:30.09050496Z"}
